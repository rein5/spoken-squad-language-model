{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35463607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForQuestionAnswering, default_data_collator, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from huggingface_hub import Repository, get_full_repo_name, notebook_login\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import collections\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06779b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SpokenSQuAD data...\n",
      "Downloading and preparing dataset json/default to C:/Users/FJ/.cache/huggingface/datasets/json/default-1411918a34a1e32f/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eabb51cbfc349dab9d8f117e6299de0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a783be08f7404aa7027455a925a095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_WER44 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_WER54 split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to C:/Users/FJ/.cache/huggingface/datasets/json/default-1411918a34a1e32f/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764dc05538d04727a611c1b6a588869a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SpokenSQuAD dataset files\n",
    "spoken_train = 'spoken_train-v1.1.json'\n",
    "spoken_test = 'spoken_test-v1.1.json'\n",
    "spoken_test_WER44 = 'spoken_test-v1.1_WER44.json'\n",
    "spoken_test_WER54 = 'spoken_test-v1.1_WER54.json'\n",
    "\n",
    "# function to re-format json data\n",
    "def reformat_json(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    \n",
    "    examples = []\n",
    "    # iterate over 'data' list\n",
    "    for elem in json_data['data']:\n",
    "        title = elem['title']\n",
    "\n",
    "        # iterate over paragraphs\n",
    "        for paragraph in elem['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "\n",
    "            # iterate over question-answers for this paragraph\n",
    "            for qa in paragraph['qas']:\n",
    "                example = {}\n",
    "                example['id'] = qa['id']\n",
    "                example['title'] = title.strip()\n",
    "                example['context'] = context.strip()\n",
    "                example['question'] = qa['question'].strip()\n",
    "                example['answers'] = {}\n",
    "                example['answers']['answer_start'] = [answer[\"answer_start\"] for answer in qa['answers']]\n",
    "                example['answers']['text'] = [answer[\"text\"] for answer in qa['answers']]\n",
    "                examples.append(example)\n",
    "    \n",
    "    out_dict = {'data': examples}\n",
    "\n",
    "    output_json_file = 'out_'+json_file\n",
    "    with open(output_json_file, 'w') as f:\n",
    "        json.dump(out_dict, f)\n",
    "\n",
    "    return output_json_file\n",
    "\n",
    "\n",
    "print(\"Loading SpokenSQuAD data...\")\n",
    "\n",
    "# reformat json data\n",
    "spoken_train = reformat_json(spoken_train)\n",
    "spoken_test = reformat_json(spoken_test)\n",
    "spoken_test_WER44 = reformat_json(spoken_test_WER44)\n",
    "spoken_test_WER54 = reformat_json(spoken_test_WER54)\n",
    "\n",
    "spoken_squad_dataset = load_dataset('json',\n",
    "                                    data_files= { 'train': spoken_train,\n",
    "                                                  'validation': spoken_test,         # NO NOISE: 22.73% WER\n",
    "                                                  'test_WER44': spoken_test_WER44,   # NOISE V1: 44.22% WER\n",
    "                                                  'test_WER54': spoken_test_WER54 }, # NOISE V2: 54.82% WER\n",
    "                                    field = 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85bc3e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instantiating Model and Tokenizer...\n",
      "Model: rein5/bert-base-uncased-finetuned-spoken-squad\n",
      "\n",
      "Model Architecture: BERT (base, uncased) + Linear head (2 output logits):\n",
      "BertForQuestionAnswering(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (qa_outputs): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### Model fine-tuned from bert-base-uncased\n",
    "\n",
    "#model_checkpoint = \"bert-base-uncased\"\n",
    "model_checkpoint = \"rein5/bert-base-uncased-finetuned-spoken-squad\"\n",
    "print(\"Instantiating Model and Tokenizer...\")\n",
    "print(\"Model: \" + model_checkpoint)\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "print(\"\\nModel Architecture: BERT (base, uncased) + Linear head (2 output logits):\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e66c03dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/37111 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_length = 384 \n",
    "stride = 64\n",
    "\n",
    "\"\"\" \n",
    "    Function to preprocess the training examples. It performs the following operations:  \n",
    "        - tokenize examples into question-context token sequences of the form: \n",
    "            [CLS] question [SEP] context [SEP]         \n",
    "        - apply windowing with given stride\n",
    "        - compute output labels (start_index, end_index)\n",
    "            - if answer not fully within windowed context, set label to (0, 0)\n",
    "\"\"\"\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [question.strip() for question in examples['question']]\n",
    "    inputs = tokenizer(\n",
    "        questions, \n",
    "        examples['context'],\n",
    "        max_length = max_length,\n",
    "        truncation = 'only_second',\n",
    "        stride = stride, \n",
    "        return_overflowing_tokens = True,\n",
    "        return_offsets_mapping=True, \n",
    "        padding = 'max_length'\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop('offset_mapping')\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping')\n",
    "    answers = examples['answers']\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer['answer_start'][0]\n",
    "        end_char = answer['answer_start'][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # find start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1: \n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # if answer not fully inside context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "    \n",
    "    inputs['start_positions'] = start_positions\n",
    "    inputs['end_positions'] = end_positions\n",
    "    return inputs\n",
    "\n",
    "\n",
    "print(\"Preprocessing training data...\")\n",
    "\n",
    "train_dataset = spoken_squad_dataset['train'].map(\n",
    "    preprocess_training_examples,\n",
    "    batched = True,\n",
    "    remove_columns=spoken_squad_dataset['train'].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580329f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing test data (NO NOISE: 22.73% WER)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing V1 noise test data (44.22% WER)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing V2 noise test data (54.82% WER)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5351 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'offset_mapping', 'example_id'],\n",
      "    num_rows: 5423\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# function to preprocess validation/test examples (performs tokenization, windowing)\n",
    "def process_validation_examples(examples):\n",
    "    questions = [question.strip() for question in examples['question']]\n",
    "    inputs = tokenizer(\n",
    "        questions, \n",
    "        examples['context'],\n",
    "        max_length = max_length,\n",
    "        truncation = 'only_second',\n",
    "        stride = stride, \n",
    "        return_overflowing_tokens = True,\n",
    "        return_offsets_mapping=True, \n",
    "        padding = 'max_length'\n",
    "    )\n",
    "\n",
    "    sample_map = inputs.pop('overflow_to_sample_mapping')\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs['input_ids'])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offsets = inputs['offset_mapping'][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            offset if sequence_ids[k] == 1 else None for k, offset in enumerate(offsets)\n",
    "        ]\n",
    "\n",
    "    inputs['example_id'] = example_ids\n",
    "    return inputs\n",
    "\n",
    "\n",
    "print(\"Preprocessing test data (NO NOISE: 22.73% WER)...\")\n",
    "validation_dataset = spoken_squad_dataset['validation'].map(\n",
    "    process_validation_examples,\n",
    "    batched = True,\n",
    "    remove_columns=spoken_squad_dataset['validation'].column_names\n",
    ")\n",
    "\n",
    "print(\"Preprocessing V1 noise test data (44.22% WER)...\")\n",
    "test_WER44_dataset = spoken_squad_dataset['test_WER44'].map(\n",
    "    process_validation_examples,\n",
    "    batched = True,\n",
    "    remove_columns=spoken_squad_dataset['test_WER44'].column_names\n",
    ")\n",
    "\n",
    "print(\"Preprocessing V2 noise test data (54.82% WER)...\")\n",
    "test_WER54_dataset = spoken_squad_dataset['test_WER54'].map(\n",
    "    process_validation_examples,\n",
    "    batched = True,\n",
    "    remove_columns=spoken_squad_dataset['test_WER54'].column_names\n",
    ")\n",
    "\n",
    "\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a505c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"squad\")\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features): \n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "    \n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "        \n",
    "        # loop thru all features associated with example ID\n",
    "        for feature_index in example_to_features[example_id]: \n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "            \n",
    "            start_indexes = np.argsort(start_logit)[-1: -n_best - 1: -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1: -n_best - 1: -1].tolist()\n",
    "            for start_index in start_indexes: \n",
    "                for end_index in end_indexes: \n",
    "                    # skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None: \n",
    "                        continue\n",
    "                    # skip answers with a length that is either <0 or >max_answer_length\n",
    "                    if end_index < start_index or end_index-start_index+1 > max_answer_length: \n",
    "                        continue\n",
    "                    \n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index]\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "        # select answer with best score\n",
    "        if len(answers) > 0: \n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else: \n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "        \n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3915a992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train dataloader...\n",
      "Creating validation dataloader...\n",
      "Creating test V1 dataloader...\n",
      "Creating test V2 dataloader...\n"
     ]
    }
   ],
   "source": [
    "train_dataset.set_format(\"torch\")\n",
    "validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "validation_set.set_format(\"torch\")\n",
    "test_WER44_set = test_WER44_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "test_WER44_set.set_format(\"torch\")\n",
    "test_WER54_set = test_WER54_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "test_WER54_set.set_format(\"torch\")\n",
    "\n",
    "print(\"Creating train dataloader...\")\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    shuffle = True, \n",
    "    collate_fn=default_data_collator, \n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "print(\"Creating validation dataloader...\")\n",
    "eval_dataloader = DataLoader(\n",
    "    validation_set, collate_fn=default_data_collator, batch_size=8\n",
    ")\n",
    "print(\"Creating test V1 dataloader...\")\n",
    "test_WER44_dataloader = DataLoader(\n",
    "    test_WER44_set, collate_fn=default_data_collator, batch_size=8\n",
    ")\n",
    "print(\"Creating test V2 dataloader...\")\n",
    "test_WER54_dataloader = DataLoader(\n",
    "    test_WER54_set, collate_fn=default_data_collator, batch_size=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffe7717c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"bert-base-uncased-finetuned-spoken-squad\"\n",
    "\n",
    "\"\"\" ### CODE USED TO UPLOAD THE FINETUNED MODEL TO \n",
    "    ###    huggingface.co/rein5/bert-base-uncased-finetuned-spoken-squad\n",
    "    \n",
    "notebook_login()\n",
    "\n",
    "model_name = output_dir\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "print(\"Trained model checkpoints uploaded to: \" + repo_name)\n",
    "\n",
    "print(\"Cloning model repo...\")\n",
    "repo = Repository(output_dir, clone_from=repo_name)\n",
    "\n",
    "upload_to_hub = True\n",
    "\"\"\"\n",
    "upload_to_hub = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b290a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on Test Set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cfdbccc2e74890ac1a7b2bcfdc9ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/678 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87da40529ce34459b83ec3f84aa2e6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on Test V1 Set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1078a0ee7e498cb84fc18541ff8bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631bba059de448b6b06bde9ec26bd692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on Test V2 Set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57d039b2c08457fae32e7f2191d4cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/679 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb13cc0856e4d519f492b38f3f54d89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= RESULTS =============\n",
      "Test Set    (NO NOISE - 22.73% WER) - exact match: 64.2309848626425, F1 score: 74.28583407367609\n",
      "Test V1 Set (V1 NOISE - 44.22% WER) - exact match: 40.72136049336573, F1 score: 54.93843728701469\n",
      "Test V2 Set (V2 NOISE - 54.82% WER) - exact match: 28.499345916651095, F1 score: 41.412023581649585\n",
      "===================================\n"
     ]
    }
   ],
   "source": [
    "# function to evaluate the model on a give dataset \n",
    "def evaluate_model(model, dataloader, dataset, dataset_before_preprocessing, accelerator=None):\n",
    "    if not accelerator: \n",
    "        accelerator = Accelerator(mixed_precision='fp16')\n",
    "        model, dataloader = accelerator.prepare(\n",
    "            model, dataloader\n",
    "        )\n",
    "    \n",
    "    model.eval()\n",
    "    start_logits = []\n",
    "    end_logits = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        with torch.no_grad(): \n",
    "            outputs = model(**batch)\n",
    "\n",
    "        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())\n",
    "        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())\n",
    "\n",
    "    start_logits = np.concatenate(start_logits)\n",
    "    end_logits = np.concatenate(end_logits)\n",
    "    start_logits = start_logits[: len(dataset)]\n",
    "    end_logits = end_logits[: len(dataset)]\n",
    "\n",
    "    metrics = compute_metrics(\n",
    "        start_logits, end_logits, dataset, dataset_before_preprocessing\n",
    "    )\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "### TRAINING LOOP\n",
    "def train_model(model=model, train_dataloader=train_dataloader, eval_dataloader=eval_dataloader, epochs = 1):\n",
    "    training_steps = epochs * len(train_dataloader)\n",
    "\n",
    "    accelerator = Accelerator(mixed_precision='fp16')\n",
    "    optimizer = AdamW(model.parameters(), lr = 2e-5)\n",
    "\n",
    "    model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "        model, optimizer, train_dataloader, eval_dataloader\n",
    "    )\n",
    "\n",
    "    lr_scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=training_steps,\n",
    "    )\n",
    "\n",
    "    progress_bar = tqdm(range(training_steps))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # train for 1 epoch\n",
    "        model.train()\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        # evaluate after each epoch \n",
    "        accelerator.print(\"Evaluation...\")\n",
    "        metrics = evaluate_model(model, eval_dataloader, validation_dataset, spoken_squad_dataset['validation'], accelerator)\n",
    "        print(f\"epoch {epoch}:\", metrics)\n",
    "\n",
    "        # save and upload \n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "        if upload_to_hub and accelerator.is_main_process: \n",
    "            tokenizer.save_pretrained(output_dir)\n",
    "            repo.push_to_hub(\n",
    "                commit_message = f\"Training in progress epoch {epoch}\", blocking=False\n",
    "            )\n",
    "\n",
    "### UNCOMMENT TO TRAIN THE MODEL FOR 1 MORE EPOCH\n",
    "#print(\"Fine-tuning the model...\")\n",
    "#notebook_launcher(train_model, num_processes=1) # change num_processes value for multi-gpu training\n",
    "###\n",
    "\n",
    "### EVALUATE FINETUNED MODEL \n",
    "print(\"Evaluating model on Test Set...\")\n",
    "test_metrics = evaluate_model(model, eval_dataloader, validation_dataset, spoken_squad_dataset['validation'])\n",
    "print(\"Evaluating model on Test V1 Set...\")\n",
    "test_v1_metrics = evaluate_model(model, test_WER44_dataloader, test_WER44_dataset, spoken_squad_dataset['test_WER44'])\n",
    "print(\"Evaluating model on Test V2 Set...\")\n",
    "test_v2_metrics = evaluate_model(model, test_WER54_dataloader, test_WER54_dataset, spoken_squad_dataset['test_WER54'])\n",
    "\n",
    "print(\"============= RESULTS =============\")\n",
    "print(\"Test Set    (NO NOISE - 22.73% WER) - exact match: \" + str(test_metrics['exact_match']) + \", F1 score: \" + str(test_metrics['f1']))\n",
    "print(\"Test V1 Set (V1 NOISE - 44.22% WER) - exact match: \" + str(test_v1_metrics['exact_match']) + \", F1 score: \" + str(test_v1_metrics['f1']))\n",
    "print(\"Test V2 Set (V2 NOISE - 54.82% WER) - exact match: \" + str(test_v2_metrics['exact_match']) + \", F1 score: \" + str(test_v2_metrics['f1']))\n",
    "print(\"===================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69c2afa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
